{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517df628",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "#set the video you want to use:\n",
    "YOUTUBE_VIDEO = \"https://www.youtube.com/watch?v=cdiD-9MMpb0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "5951c1ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the ChatOpenAI class for calling OpenAI chat models (like GPT-3.5, GPT-4) through LangChain\n",
    "from langchain_openai.chat_models import ChatOpenAI\n",
    "\n",
    "# Initialize an OpenAI chat model instance.\n",
    "model = ChatOpenAI(openai_api_key = OPENAI_API_KEY, model='gpt-3.5-turbo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "2e1339a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#uncomment below to test:\n",
    "#model.invoke(\"what is the best soccer team?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "82efd240",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Import an output parser that converts the model's structured output into a plain Python string.\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "# Create an instance of the string output parser.\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# User Input → OpenAI Model → Parsed String Output\n",
    "chain = model | parser\n",
    "\n",
    "# uncomment below to test:\n",
    "#chain.invoke('what is 2+2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "d9f0c1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import ChatPromptTemplate, which lets you define reusable prompt templates with placeholders (variables) like {context} and {question}.\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "# Define a template that tells the model how to behave.\n",
    "template = \"\"\"\n",
    "Answer the question based on the context below. If you can't answer the question, reply \"Quack Quack\".\n",
    "\n",
    "Context: {context}\n",
    "\n",
    "Question: {question}\n",
    "\"\"\"\n",
    "\n",
    "# Convert the raw text prompt into a structured LangChain ChatPromptTemplate.\n",
    "prompt = ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "bdceda83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'White'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Input → Prompt → Model → Text Parser → Final Answer\n",
    "chain = prompt | model | parser\n",
    "\n",
    "# Test the chain by providing concrete values for the prompt variables.\n",
    "chain.invoke({\n",
    "    \"context\": \"I love white cars\",\n",
    "    \"question\": \"what color should my next car be?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "ddcecda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import whisper\n",
    "from pytubefix import YouTube\n",
    "\n",
    "# Only generate the transcription if it doesn't already exist. This prevents you from re-downloading and re-transcribing the same video every time you run the script.\n",
    "if not os.path.exists(\"transcription.txt\"):\n",
    "    youtube = YouTube(YOUTUBE_VIDEO) # Initialize a YouTube object using the video URL. 'YOUTUBE_VIDEO' must be defined earlier in your code.\n",
    "    audio = youtube.streams.filter(only_audio=True).first()  # Select the audio-only stream (no video) for faster download and smaller file size.\n",
    "\n",
    "    #load the base model. not the most accurate but fast\n",
    "    whisper_model = whisper.load_model(\"base\")\n",
    "\n",
    "    # Create a temporary directory to store the downloaded audio file. The directory is automatically cleaned up after the 'with' block exits.\n",
    "    with tempfile.TemporaryDirectory() as tmpdir:\n",
    "        file = audio.download(output_path=tmpdir) ## Download the audio stream into the temporary directory.\n",
    "        transcription = whisper_model.transcribe(file, fp16=False)[\"text\"].strip()         # Transcribe the audio using Whisper. fp16=False ensures compatibility on CPUs (prevents GPU-only errors). The result is a dict; we extract the \"text\" field and strip whitespace.\n",
    "\n",
    "        # Save the transcription to a text file for later retrieval. This makes your script much faster on repeated runs.\n",
    "        with open(\"transcription.txt\", \"w\") as file:\n",
    "            file.write(transcription)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "09c50d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"I think it's possible that physics has exploits and we should be trying to find them. arranging some\""
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open the saved transcription file and read its full content as a string. # This is used when the transcript was already generated earlier, so we don't need to re-run Whisper every time.\n",
    "with open(\"transcription.txt\") as file:\n",
    "    transcription = file.read()\n",
    "\n",
    "# Display the first 100 characters of the transcription.\n",
    "transcription[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "4997153e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 400 - {'error': {'message': \"This model's maximum context length is 16385 tokens. However, your messages resulted in 47046 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}\n"
     ]
    }
   ],
   "source": [
    "# here we try to invoke the function, but the transcription is too big for the model so we get an error\n",
    "try:\n",
    "    chain.invoke({\n",
    "        \"context\": transcription,\n",
    "        \"question\": \"Is reading paper a good idea?\"\n",
    "    })\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "380eef98",
   "metadata": {},
   "outputs": [],
   "source": [
    "#We need to split the documents. This load the text file into langchain for splitting \n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "loader = TextLoader(\"transcription.txt\")\n",
    "text_documents = loader.load()\n",
    "\n",
    "#uncomment to test:\n",
    "#text_documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "1d4989a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'transcription.txt'}, page_content=\"I think it's possible that physics has exploits and we should be trying to find them. arranging some kind of a crazy quantum mechanical system that somehow gives you buffer overflow, somehow gives you a rounding error in the floating point. Synthetic intelligences are kind of like the next stage of development. And I don't know where it leads to. Like at some point, I suspect the universe is some kind of a puzzle. These synthetic AIs will uncover that puzzle and solve it. The following is a conversation with Andre Kappathi, previously the director of AI at Tesla. And before that, at OpenAI and Stanford, he is one of the greatest scientist engineers and educators in the history of artificial intelligence. This is the Lex Friedman podcast to support it. Please check out our sponsors and now to your friends. Here's Andre Kappathi. What is a neural network? And what does it seem to do such a surprisingly good job of learning? What is a neural network? It's a mathematical abstraction of the\"),\n",
       " Document(metadata={'source': 'transcription.txt'}, page_content=\"abstraction of the brain. I would say that's how it was originally developed. At the end of the day, it's a mathematical expression. And it's a fairly simple mathematical expression when you get down to it. It's basically a sequence of meter smoke applies, whichever link dot products mathematically. And some non-linearities throw them in. And so it's a very simple mathematical expression. And it's got knobs in it. Many knobs. Many knobs. And these knobs are loosely related to basically the synapses in your brain. They're trainable, they're modifiable. And so the idea is we need to find the setting of the knobs that makes the neural net do whatever you want it to do, like classify images and so on. And so there's not too much mystery I would say in it. Like you might think that basically don't want to end out with too much meaning with respect to the brain and how it works. It's really just a complicated mathematical expression with knobs. And those knobs need a proper setting for it\"),\n",
       " Document(metadata={'source': 'transcription.txt'}, page_content=\"setting for it to do something desirable. Yeah, but poetry is just the collection of letters with spaces. But it can make us feel a certain way. And in that same way, when you get a large number of knobs together, whether it's inside the brain or inside a computer, they seem to they seem to surprise us with their power. Yeah, I think that's fair. So basically I'm underselling it by a lot because you definitely do get very surprising emergent behaviors out of these neural nets when they're large enough and trained on complicated enough problems. Like say, for example, the next word prediction in a massive data set from the internet. And then these neural nets take on pretty surprising magical properties. Yeah, I think it's kind of interesting how much you can get out of even very simple mathematical formalism. When your brain right now is talking, is it doing next word prediction? Or is it doing something more interesting? Well, it's definitely some kind of a generative model that's a\"),\n",
       " Document(metadata={'source': 'transcription.txt'}, page_content=\"model that's a GPT-like and prompted by you. Yeah, so you're giving me a prompt and I'm kind of like responding to it in a generative way. And by yourself, perhaps a little bit like are you adding extra prompts from your own memory inside your head? Or no? Well, definitely feels like you're referencing some kind of a declarative structure of like memory and so on. And then you're putting that together with your prompt and giving away some extra. How much of what you just said has been said by you before? Nothing, basically, right? No, but if you actually look at all the words you've ever said in your life and you do a search, you'll probably said a lot of the same words in the same order before. Yeah, could be. I mean, I'm using phrases that are common, etc. But I'm remixing it into a pretty sort of unique sentence at the end of the day. But you're right, definitely, there's like a ton of remixing. Why you didn't, you just like Magnus Carlson said, I'm rated 2,900, whatever, which is\"),\n",
       " Document(metadata={'source': 'transcription.txt'}, page_content=\"whatever, which is pretty decent. I think you're talking very, you're not giving enough credit to neural nets here. Why do they seem to, what's your best intuition about this emergent behavior? I mean, it's kind of interesting because I'm simultaneously underselling them. But I also feel like there's an element to which I'm over like, it's actually kind of incredible that you can get so much emergent magical behavior out of them, despite them being so simple mathematically. So I think those are kind of like two surprising statements that are kind of just juxtaposed together. And I think basically what it is is we are actually fairly good at optimizing these neural nets. And when you give them a hard enough problem, they are forced to learn very interesting solutions in the optimization. And those solutions basically have these emergent properties that are very interesting. There's wisdom and knowledge in the knobs. And so this representation that's in the knobs doesn't make sense to\")]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import a text splitter designed for splitting long documents into smaller chunks that work well with language models and embeddings.\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Create a text splitter with:\n",
    "# - chunk_size=1000: each chunk will contain ~1000 characters\n",
    "# - chunk_overlap=20: each chunk will overlap 20 characters with the next one\n",
    "# Overlap helps preserve context continuity across chunks, improving retrieval quality.\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=20)\n",
    "\n",
    "# Split the list of Document objects into many smaller Documents.\n",
    "# Each resulting Document has:\n",
    "# - a chunk of text\n",
    "# - metadata referencing the source file\n",
    "documents = text_splitter.split_documents(text_documents)\n",
    "\n",
    "# Display the first 5 chunks for inspection.\n",
    "text_splitter.split_documents(text_documents)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "ac437f5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Pinecone vector store wrapper for LangChain. This allows LangChain to interact with your Pinecone index using the standard VectorStore interface.\n",
    "from langchain_pinecone import PineconeVectorStore\n",
    "\n",
    "# Name of your Pinecone index. You must have already created this index in your Pinecone project dashboard.\n",
    "index_name = \"youtube-rag\"\n",
    "\n",
    "# Create a Pinecone vector store and upload all of your embedded document chunks.\n",
    "\n",
    "# This step performs:\n",
    "# 1. Embedding each chunk (if not already embedded)\n",
    "# 2. Uploading vectors + metadata into Pinecone\n",
    "# 3. Returning a VectorStore object wired to Pinecone\n",
    "\n",
    "pinecone = PineconeVectorStore.from_documents(\n",
    "    documents, embeddings, index_name=index_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "81f0a3b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'transcription.txt'}, page_content=\"It's like high quality audio and you're speaking usually pretty clearly. I don't know what open AI's plans are either. Yeah, there's always fun projects basically. And stable diffusion also is opening up a huge amount of experimentation. I would say in the visual realm and generating images and videos and movies. I'll think like videos now. And so that's going to be pretty crazy. That's going to almost certainly work and it's going to be really interesting when the cost of content creation is going to fall to zero. You used to need a painter for a few months to paint a thing and now it's going to be speak to your phone to get your video. So Hollywood will start using it to generate scenes, which completely opens up. Yeah, so you can make a movie like Avatar eventually for under a million dollars. Much less. Maybe just by talking to your phone. I mean, I know it sounds kind of crazy. And then there'd be some voting mechanism. Like how do you have a, like, would there be a show on\"),\n",
       " Document(metadata={'source': 'transcription.txt'}, page_content=\"It's like high quality audio and you're speaking usually pretty clearly. I don't know what open AI's plans are either. Yeah, there's always fun projects basically. And stable diffusion also is opening up a huge amount of experimentation. I would say in the visual realm and generating images and videos and movies. I'll think like videos now. And so that's going to be pretty crazy. That's going to almost certainly work and it's going to be really interesting when the cost of content creation is going to fall to zero. You used to need a painter for a few months to paint a thing and now it's going to be speak to your phone to get your video. So Hollywood will start using it to generate scenes, which completely opens up. Yeah, so you can make a movie like Avatar eventually for under a million dollars. Much less. Maybe just by talking to your phone. I mean, I know it sounds kind of crazy. And then there'd be some voting mechanism. Like how do you have a, like, would there be a show on\"),\n",
       " Document(metadata={'source': 'transcription.txt'}, page_content=\"It's like high quality audio and you're speaking usually pretty clearly. I don't know what open AI's plans are either. Yeah, there's always fun projects basically. And stable diffusion also is opening up a huge amount of experimentation. I would say in the visual realm and generating images and videos and movies. I'll think like videos now. And so that's going to be pretty crazy. That's going to almost certainly work and it's going to be really interesting when the cost of content creation is going to fall to zero. You used to need a painter for a few months to paint a thing and now it's going to be speak to your phone to get your video. So Hollywood will start using it to generate scenes, which completely opens up. Yeah, so you can make a movie like Avatar eventually for under a million dollars. Much less. Maybe just by talking to your phone. I mean, I know it sounds kind of crazy. And then there'd be some voting mechanism. Like how do you have a, like, would there be a show on\")]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform a similarity search in the Pinecone vector store. This retrieves the chunks whose embeddings are most similar to the embedding of the query.\n",
    "# The result is a list of Document objects ranked by relevance. We display only the top 3 matches for inspection.\n",
    "pinecone.similarity_search(\"What is Hollywood going to start doing?\")[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "634cde03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hollywood is going to start using stable diffusion to generate scenes, which will completely open up new possibilities for content creation. This means that Hollywood will be able to make movies like Avatar for under a million dollars, and possibly even less, just by talking to a phone. This technology will drastically reduce the cost of content creation and revolutionize the way movies are made.'"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.schema.runnable import RunnablePassthrough\n",
    "\n",
    "# Build a full RAG chain using LangChain's composable \"Runnable\" syntax. Each step pipes its output into the next.\n",
    "chain = (\n",
    "    {\"context\": pinecone.as_retriever(), \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | model\n",
    "    | parser\n",
    ")\n",
    "\n",
    "# Run the full RAG pipeline by simply passing a question.\n",
    "# Under the hood:\n",
    "#   1. The question is embedded\n",
    "#   2. Pinecone finds similar chunks\n",
    "#   3. These chunks are inserted into your prompt\n",
    "#   4. The model answers using ONLY the retrieved context\n",
    "chain.invoke(\"What is hollywood going to start doing? in details\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
